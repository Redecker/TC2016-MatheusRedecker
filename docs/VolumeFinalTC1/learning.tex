%!TEX root = volumeFinal.tex 
\chapter{\label{chap:aprendizado}Aprendizado}
 
Para os humanos o aprendizado ocorre durante toda a vida. 
O aprendizado é o ato de adquirir novos conhecimentos, ou modificar conhecimentos já existentes ou ainda adquirir uma experiencia por repetição do ato de forma incorreta. 
Aprendizado pode variar de adquirir conhecimento de tarefas simples, como decorando um numero de telefone, até tarefas mais complicadas, como a formulação de novas teorias \cite{intelligence2003modern}. 

\section{Aprendizado de Máquina} 

A área na computação que estudo esse aprendizado de forma computacional é o aprendizado de maquina, melhor conhecida como \textit{machine learning}. A definição de aprendizado de maquina proposta por Tom Mitchell \cite{Mitchell1997ML} é a seguinte:

\begin{quote}
	Definição: Um programa de computador é dito que aprende de uma experiencia E com relação a alguma classe de tarefas T, e medida de performance P, se essa performance sobre as tarefas em T, medida por P, melhora com a experiencia E.
\end{quote}

Essa definição mostra que o sistema aprimora seu conjunto de tarefas T com uma performance P através de experiencias E. Ou seja, um sistema baseado em aprendizado de maquina deve, através de experiencias, ter um ganho nas informações para solucionar os seus problemas. Para começar a resolver um problema utilizando aprendizado de maquina é preciso escolher qual experiencia será aprendida pelo sistema \cite{Mitchell1997ML}. Para isso existem algumas técnicas que tratam aprendizado de maquina com objetivos diferentes \cite{intelligence2003modern}. Alguma das técnicas são: 
\begin{itemize}
	\item Aprendizado supervisionado: Aprender através de algum conjunto de exemplos a realizar a classificação de algum problema. Cada problema é mapeado para uma saída. 
	\item Aprendizado não supervisionado: Aprender através das observações, algum pedrão ou regularidade, para classificar em grupos os problemas.
	\item Aprendizado por reforço: Aprender através das execuções, bem ou mal sucedidas. Aprende quais ações são melhores de ser executadas.
\end{itemize}

Cada tipo de aprendizado é utilizado pode ser usado para uma aplicação especifica, mas existem casos em que a combinação das técnicas se mostra mais eficaz. Um exemplo apresentado por \cite{intelligence2003modern} é o reconhecimento de idade por fotos, para essa tarefa são necessários amostras de fotos com as idades, então a técnica que se encaixa é aprendizado supervisionado, mas existem ruídos aleatórios nas imagens que fazem com que a precisão da abordagem caia, para superar esse problema pode ser combinado aprendizado supervisionado com o não supervisionado.

\section{Aprendizado por Reforço}

O aprendizado por reforço também é conhecido como \textit{reinforcement learning}. Este tipo de aprendizado utiliza \textit{feedbacks}, vindas do ambiente após a sua execução, esse tipo de \textit{feedback}, é chamado de recompensa. O objetivo deste aprendizado é usar as recompensas obtidas nas observações para aprender uma politica do ambiente ou determinar o quão boa a politica é \cite{intelligence2003modern}. 

Em jogos \textit{reinforcement learning} é um tópico que é bastante utilizado \cite{millington2009artificial}. Em um jogo essa técnica utiliza três etapas, uma para exploração da estrategia para achar as diferentes ações possíveis no jogo, uma função que disponibiliza o \textit{feedback} e diz o quão bom é cada ação, e uma regra de aprendizado que junta as outras duas etapas \cite{millington2009artificial}.

Existem dois tipos principais de aprendizado por reforço \cite{intelligence2003modern}:

\begin{itemize}
	\item Aprendizado Passivo
	\item Aprendizado Ativo
\end{itemize}

\subsection{Aprendizado passivo} 

O aprendizado passivo utiliza ambientes completamente observáveis. Com uma politica do ambiente fixa, em um estado, sempre é executado a mesma ação. O objetivo desse tipo de aprendizado é aprender o quão bom é a politica, e para isso se deseja aprender a função de utilidade para cada estado, dada por \textit{utility(state)} \cite{intelligence2003modern}.

Um agente que utiliza essa técnica realiza várias execuções do ambiente com a politica, para descobrir a recompensa de cada estado alcançado. Em cada uma das execuções o agente começa no mesmo estado e experimenta uma sequencia diferente de caminhos para chegar no objetivo \cite{intelligence2003modern}. 



\subsection{Aprendizado ativo}

O aprendizado ativo diferente do passivo não tem uma politica fixa e a mesma deve ser aprendida. Para isso, um agente que utiliza este tipo de aprendizado precisa decidir quais ações tomar, isso faz com que o agente precise aprender o modelo de transição para cada um dos estados e ações \cite{intelligence2003modern}. 

Um método para conseguir definir a politica do ambiente é chamado de \textit{Q-learning}. O objetivo desse método é aprender uma utilidade ligada a um estado e uma ação, denotada por uma tabela $Q[s,a]$, através da informação de recompensa para cada estado. A cada entrada no mesmo par de estado e ação, a informação contida nele diminui, então uma tabela de frequência é necessária para contabilizar a frequência dos pares, detonada por $N[s, a]$. $\alpha$ é o fator de aprendizado para cada repetição de estado, quanto menor ele for, menos ele aprende de estados que já tenham sido visitado. O algoritmo \ref{alg:qlearning} apresenta o método de \textit{Q-learning} para um agente.

\begin{algorithm}
	\caption{Q-Learning}
	\label{alg:qlearning}
	\begin{algorithmic}[]	
		\Function{Q-Learning}{$state, reward$}
		\If {$terminal(state)$}
		\State	\Return $Q[s, None] = reward$
		\EndIf
		\If {$state$ is not null}
		\State {increment $N[s, a]$}
		\State $Q[s, a] = Q[s, a] + \alpha(N[s, a]) (r + \gamma max_{a'} Q[s', a'] - Q[s, a])$
		\State s = $s'$
		\State a = $argmax_{a'} f(Q[s', a'], N[s', a'])$
		\State r = $r'$
		\EndIf	
		\EndFunction
	\end{algorithmic}
\end{algorithm}

Com a informação de cada par de estado e ação, é possível determinar qual sequencia de ações é a melhor possível para o agente.

%Para que isso aconteça, cada estado contém uma utilidade, que mostra o quão desejável é este estado, pode ser um desejo bom ou um ruim. Com essa informação é possível determinar, dado as ações disponíveis no estado, qual ação o sistema deve escolher para seguir a execução. 
